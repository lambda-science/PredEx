{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from glob import glob\n",
    "import json\n",
    "experiments = glob(\"exstracs/N*\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "dataTracking = []\n",
    "rules = []\n",
    "experiments_list = []\n",
    "for index, value in enumerate(experiments):\n",
    "    dataTracking.append(pd.read_csv(os.path.join(value, \"iteration_results.csv\")))\n",
    "    rules.append(pd.read_csv(os.path.join(value, \"compacted_rules.csv\")))\n",
    "    experiments_list.append(json.load(open(os.path.join(value, \"results_data_plot.json\"))))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(15,15))\n",
    "ax = ax.flatten()\n",
    "for index, dict_expe in enumerate(experiments_list):\n",
    "    train_scores_mean = np.mean(dict_expe[\"train_scores\"], axis=1)\n",
    "    test_scores_mean = np.mean(dict_expe[\"test_scores\"], axis=1)\n",
    "    train_scores_std = np.std(dict_expe[\"train_scores\"], axis=1)\n",
    "    test_scores_std = np.std(dict_expe[\"test_scores\"], axis=1)\n",
    "    train_sizes = dict_expe[\"train_sizes\"]\n",
    "    ax[index].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                    label=\"Training score\")\n",
    "    ax[index].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                    label=\"Cross-validation score\")\n",
    "    ax[index].fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                            train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                            color=\"r\")\n",
    "    ax[index].fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                            test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                            color=\"g\")\n",
    "    ax[index].set_ylim(0,1.05)\n",
    "    ax[index].set_title(\"Learning Curve Exstracs (\"+dict_expe[\"name\"]+\"). Mean Acc +- 1 std\")\n",
    "    ax[index].set_xlabel(\"Training Examples\")\n",
    "    ax[index].set_ylabel(\"Accuracy Score\")\n",
    "    ax[index].legend(loc=\"lower right\")\n",
    "    ax[index].grid()\n",
    "    #plt.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def movingAvg(a,threshold=300):\n",
    "    weights = np.repeat(1.0,threshold)/threshold\n",
    "    conv = np.convolve(a,weights,'valid')\n",
    "    return np.append(conv,np.full(threshold-1,conv[conv.size-1]),)\n",
    "\n",
    "def plot_metrics_exstracs(dataTracking, experiments_list, rules):\n",
    "    iterations = dataTracking[\"Iteration\"].values\n",
    "    accuracy = dataTracking['Accuracy (approx)'].values\n",
    "    generality = dataTracking['Average Population Generality'].values\n",
    "    macroPop = dataTracking[\"Macropopulation Size\"].values\n",
    "    microPop = dataTracking[\"Micropopulation Size\"].values\n",
    "    mSize = dataTracking[\"Match Set Size\"].values\n",
    "    cSize = dataTracking[\"Correct Set Size\"].values\n",
    "    experience = dataTracking[\"Average Iteration Age of Correct Set Classifiers\"].values\n",
    "    subsumption = dataTracking[\"# Classifiers Subsumed in Iteration\"].values\n",
    "    crossover = dataTracking[\"# Crossover Operations Performed in Iteration\"].values\n",
    "    mutation = dataTracking[\"# Mutation Operations Performed in Iteration\"].values\n",
    "    covering = dataTracking[\"# Covering Operations Performed in Iteration\"].values\n",
    "    deletion = dataTracking[\"# Deletion Operations Performed in Iteration\"].values\n",
    "    rc = dataTracking[\"# Rules Removed via Rule Compaction\"].values\n",
    "\n",
    "    gTime = dataTracking[\"Total Global Time\"].values\n",
    "    mTime = dataTracking[\"Total Matching Time\"].values\n",
    "    covTime = dataTracking[\"Total Covering Time\"].values\n",
    "    crossTime = dataTracking[\"Total Crossover Time\"].values\n",
    "    covTime = dataTracking[\"Total Covering Time\"].values\n",
    "    mutTime = dataTracking[\"Total Mutation Time\"].values\n",
    "    atTime = dataTracking[\"Total Attribute Tracking Time\"].values\n",
    "    initTime = dataTracking[\"Total Model Initialization Time\"].values\n",
    "    rcTime = dataTracking[\"Total Rule Compaction Time\"].values\n",
    "    delTime = dataTracking[\"Total Deletion Time\"].values\n",
    "    subTime = dataTracking[\"Total Subsumption Time\"].values\n",
    "    selTime = dataTracking[\"Total Selection Time\"].values\n",
    "    evalTime = dataTracking[\"Total Evaluation Time\"].values\n",
    "\n",
    "    fig, ax = plt.subplots(2, 3, figsize=(20,10))\n",
    "    ax[0,0].plot(iterations,accuracy,label=\"approx accuracy\")\n",
    "    ax[0,0].plot(iterations,generality,label=\"avg generality\")\n",
    "    ax[0,0].set_xlabel('Iteration')\n",
    "    ax[0,0].set_ylabel('accuracy/generality')\n",
    "    ax[0,0].set_ylim(0, 1.01)\n",
    "    ax[0,0].legend(loc=\"best\")\n",
    "\n",
    "    ax[0,1].plot(iterations,macroPop,label=\"macroPop Size\")\n",
    "    ax[0,1].plot(iterations,microPop,label=\"microPop Size\")\n",
    "    ax[0,1].set_xlabel('Iteration')\n",
    "    ax[0,1].set_ylabel('Macro/MicroPop Size')\n",
    "    ax[0,1].legend(loc=\"best\")\n",
    "\n",
    "    ax[0,2].plot(iterations,mSize,label=\"[M] size\")\n",
    "    ax[0,2].plot(iterations,cSize,label=\"[C] size\")\n",
    "    ax[0,2].plot(iterations,movingAvg(mSize),label=\"[M] size movingAvg\")\n",
    "    ax[0,2].plot(iterations,movingAvg(cSize),label=\"[C] size movingAvg\")\n",
    "    ax[0,2].set_xlabel('Iteration')\n",
    "    ax[0,2].set_ylabel('[M]/[C] size per iteration')\n",
    "    ax[0,2].legend(loc=\"best\")\n",
    "\n",
    "    ax[1,0].scatter(iterations,experience, s=1, linewidths=0, marker=\",\")\n",
    "    ax[1,0].set_xlabel('Iteration')\n",
    "    ax[1,0].set_ylabel('Average [C] Classifier Age')\n",
    "    ax[1,0].legend(loc=\"best\")\n",
    "\n",
    "    ax[1,1].plot(iterations,np.cumsum(subsumption),label=\"Subsumption Count\")\n",
    "    ax[1,1].plot(iterations,np.cumsum(crossover),label=\"Crossover Count\")\n",
    "    ax[1,1].plot(iterations,np.cumsum(mutation),label=\"Mutation Count\")\n",
    "    ax[1,1].plot(iterations,np.cumsum(deletion),label=\"Deletion Count\")\n",
    "    ax[1,1].plot(iterations,np.cumsum(covering),label=\"Covering Count\")\n",
    "    ax[1,1].plot(iterations,np.cumsum(rc),label=\"RC Count\")\n",
    "    ax[1,1].set_xlabel('Iteration')\n",
    "    ax[1,1].set_ylabel('Cumulative Operations Count Over Iterations')\n",
    "    ax[1,1].legend(loc=\"best\")\n",
    "\n",
    "\n",
    "    ax[1,2].plot(iterations,initTime,label=\"Init Time\")\n",
    "    ax[1,2].plot(iterations,mTime+initTime,label=\"Matching Time\")\n",
    "    ax[1,2].plot(iterations,covTime+mTime+initTime,label=\"Covering Time\")\n",
    "    ax[1,2].plot(iterations,selTime+covTime+mTime+initTime,label=\"Selection Time\")\n",
    "    ax[1,2].plot(iterations,crossTime+selTime+covTime+mTime+initTime,label=\"Crossover Time\")\n",
    "    ax[1,2].plot(iterations,mutTime+crossTime+selTime+covTime+mTime+initTime,label=\"Mutation Time\")\n",
    "    ax[1,2].plot(iterations,subTime+mutTime+crossTime+selTime+covTime+mTime+initTime,label=\"Subsumption Time\")\n",
    "    ax[1,2].plot(iterations,atTime+subTime+mutTime+crossTime+selTime+covTime+mTime+initTime,label=\"AT Time\")\n",
    "    ax[1,2].plot(iterations,delTime+atTime+subTime+mutTime+crossTime+selTime+covTime+mTime+initTime,label=\"Deletion Time\")\n",
    "    ax[1,2].plot(iterations,rcTime+delTime+atTime+subTime+mutTime+crossTime+selTime+covTime+mTime+initTime,label=\"RC Time\")\n",
    "    ax[1,2].plot(iterations,evalTime+rcTime+delTime+atTime+subTime+mutTime+crossTime+selTime+covTime+mTime+initTime,label=\"Evaluation Time\")\n",
    "    ax[1,2].plot(iterations,gTime,label=\"Total Time\")\n",
    "    ax[1,2].set_xlabel('Iteration')\n",
    "    ax[1,2].set_ylabel('Cumulative Time (Stacked)')\n",
    "    ax[1,2].legend(loc=\"best\")\n",
    "    title = \"Learning Iterations Metrics for N=\"+experiments_list[\"name\"]+\"\\n Total number of rules: \" + str(len(rules)) \\\n",
    "        + \"\\n Final Training Accuracy: \" + \"{:.2f}\".format(float(experiments_list[\"final_training_acc\"]))\n",
    "    fig.suptitle(title, verticalalignment=\"center\", fontsize=\"x-large\", fontweight=\"bold\")\n",
    "    return fig, ax"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_metrics_exstracs(dataTracking[0], experiments_list[0], rules[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from skExSTraCS import ExSTraCS\n",
    "\n",
    "# Target - Data DF\n",
    "df = pd.read_csv(\"data/histo_feature.csv\")\n",
    "df = df.iloc[:,9:]\n",
    "# Drop les OTHER pour l'instant (que 3 classes)\n",
    "df = df.drop(df[df[\"conclusion\"]==\"OTHER\"].index)\n",
    "df = df.drop(df[df[\"conclusion\"]==\"UNCLEAR\"].index)\n",
    "del df[\"datetime\"]\n",
    "# Enlever les col remplis de NaN ou avec moins de 5 valeur (annotations)\n",
    "df = df.dropna(axis=1, thresh=5)\n",
    "df.fillna(0, inplace=True)\n",
    "df = df.replace({0.25:1, 0.5:1, 0.75:1})\n",
    "# Séparer les features des labels et onehot encoding des labels\n",
    "# NM:2, COM:1, UNCLEAR:4, CNM:0, OTHER:3\n",
    "X_test, Y_test = df.iloc[:,1:],df.iloc[:,0]\n",
    "label_encoder_test = LabelEncoder()\n",
    "label_encoder_test = label_encoder_test.fit(Y_test)\n",
    "label_encoded_y_test = label_encoder_test.transform(Y_test)\n",
    "\n",
    "model = ExSTraCS(reboot_filename='exstracs/N1000/exstracs_model')\n",
    "#model.post_training_rule_compaction()\n",
    "\n",
    "y_predict = model.predict(X_test.to_numpy())\n",
    "print(accuracy_score(label_encoded_y_test, y_predict))\n",
    "plot_confusion_matrix(model, X_test.to_numpy(), label_encoded_y_test)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8deeaac9d110d020cf02cb90130615d601eccb7528fd115dac771989d3df95a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}