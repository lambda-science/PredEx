{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from glob import glob\n",
    "experiments = glob(\"exstracs/*\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n500_scores = {\n",
    "    \"name\": \"N=500\",\n",
    "    \"training_score\": 0.7880952380952381,\n",
    "    \"cross_val_scoring\": [0.76923077, 0.69230769, 0.84615385, 0.83333333, 0.83333333],\n",
    "    \"train_sizes\": [5, 16, 27, 38, 50],\n",
    "    \"train_scores\": [\n",
    "        [1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "        [1.0, 1.0, 0.9375, 1.0, 1.0,],\n",
    "        [1.0, 0.96296296, 0.92592593, 1.0, 0.96296296],\n",
    "        [1.0, 0.94736842, 0.97368421, 0.97368421, 0.97368421],\n",
    "        [0.94, 0.98, 0.86, 0.92, 0.88],\n",
    "    ],\n",
    "    \"test_scores\": [\n",
    "        [0.61538462, 0.61538462, 0.38461538, 0.58333333, 0.66666667],\n",
    "        [0.69230769, 0.76923077, 0.53846154, 0.83333333, 0.83333333],\n",
    "        [0.76923077, 0.69230769, 0.69230769, 0.75, 0.83333333],\n",
    "        [0.84615385, 0.69230769, 0.92307692, 0.75, 0.75],\n",
    "        [0.76923077, 0.84615385, 0.76923077, 0.83333333, 0.83333333],\n",
    "    ],\n",
    "}\n",
    "n1000_scores = {\n",
    "    \"name\": \"N=1000\",\n",
    "    \"training_score\": 0.7999999999999999,\n",
    "    \"cross_val_scoring\": [0.76923077, 0.76923077, 0.76923077, 0.83333333, 0.83333333],\n",
    "    \"train_sizes\": [5, 16, 27, 38, 50],\n",
    "    \"train_scores\": [\n",
    "        [1.0, 1.0, 1.0, 1.0, 1.0,],\n",
    "        [1.0, 1.0, 0.9375 ,1.0, 1.0,],\n",
    "        [1.0, 0.96296296, 0.92592593, 0.96296296, 1.0,],\n",
    "        [1.0, 0.97368421, 1.0, 1.0, 0.94736842],\n",
    "        [0.98, 0.96, 0.96, 1.0, 0.92,],\n",
    "    ],\n",
    "    \"test_scores\": [\n",
    "        [0.61538462, 0.61538462, 0.46153846, 0.83333333, 0.5],\n",
    "        [0.61538462, 0.69230769, 0.61538462, 0.58333333, 0.83333333],\n",
    "        [0.84615385, 0.69230769, 0.92307692, 0.58333333, 0.83333333],\n",
    "        [0.69230769, 0.61538462, 0.76923077, 0.91666667, 0.83333333],\n",
    "        [0.76923077, 0.76923077, 0.69230769, 0.83333333, 0.83333333],\n",
    "    ],\n",
    "}\n",
    "n2000_scores = {\n",
    "    \"name\": \"N=2000\",\n",
    "    \"training_score\": 0.9333333333333332,\n",
    "    \"cross_val_scoring\": [0.84615385, 0.76923077, 0.84615385, 0.83333333, 0.83333333],\n",
    "    \"train_sizes\": [5, 16, 27, 38, 50],\n",
    "    \"train_scores\": [\n",
    "        [1.0, 1.0, 0.8, 1.0, 1.0],\n",
    "        [1.0, 1.0, 0.9375, 1.0, 1.0],\n",
    "        [1.0, 1.0, 0.96296296, 0.96296296, 1.0],\n",
    "        [1.0, 1.0, 1.0, 1.0, 1.0,],\n",
    "        [0.96, 0.96, 0.96, 1.0, 0.94,],\n",
    "    ],\n",
    "    \"test_scores\": [\n",
    "        [0.61538462, 0.84615385, 0.38461538, 0.66666667, 0.5],\n",
    "        [0.69230769, 0.84615385, 0.61538462, 0.75, 0.83333333],\n",
    "        [0.84615385, 0.76923077, 0.92307692, 0.58333333, 0.83333333],\n",
    "        [0.84615385, 0.69230769, 1.0, 0.83333333, 0.83333333],\n",
    "        [0.69230769, 1.0, 0.76923077, 0.83333333, 0.91666667],\n",
    "    ],\n",
    "}\n",
    "n3000_scores = {\n",
    "    \"name\": \"N=3000\",\n",
    "    \"training_score\": 0.9,\n",
    "    \"cross_val_scoring\": [0.84615385, 0.84615385, 0.69230769, 0.75, 0.83333333],\n",
    "    \"train_sizes\": [5, 16, 27, 38, 50],\n",
    "    \"train_scores\": [\n",
    "        [1.0, 1.0, 1.0, 1.0, 1.0,],\n",
    "        [1.0, 1.0, 1.0, 1.0, 1.0,],\n",
    "        [1.0, 1.0, 0.92592593, 1.0, 0.96296296],\n",
    "        [1.0, 0.97368421, 0.94736842, 1.0, 1.0],\n",
    "        [0.96, 0.96, 0.96, 0.98, 0.94],\n",
    "    ],\n",
    "    \"test_scores\": [\n",
    "        [0.61538462, 0.76923077, 0.38461538, 0.75, 0.5],\n",
    "        [0.69230769, 0.69230769, 0.53846154, 0.83333333, 0.83333333],\n",
    "        [0.84615385, 0.76923077, 0.69230769, 0.75, 0.75],\n",
    "        [0.84615385, 0.61538462, 0.69230769, 0.83333333, 0.83333333],\n",
    "        [0.76923077, 0.84615385, 0.84615385, 0.83333333, 0.91666667],\n",
    "    ],\n",
    "}\n",
    "experiments_list = [n500_scores, n1000_scores, n2000_scores, n3000_scores]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "dataTracking = []\n",
    "rules = []\n",
    "for index, value in enumerate(experiments):\n",
    "    dataTracking.append(pd.read_csv(os.path.join(value, \"iteration_results.csv\")))\n",
    "    rules.append(pd.read_csv(os.path.join(value, \"compated_rules.csv\")))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(15,15))\n",
    "ax = ax.flatten()\n",
    "for index, dict_expe in enumerate(experiments_list):\n",
    "    train_scores_mean = np.mean(dict_expe[\"train_scores\"], axis=1)\n",
    "    test_scores_mean = np.mean(dict_expe[\"test_scores\"], axis=1)\n",
    "    train_scores_std = np.std(dict_expe[\"train_scores\"], axis=1)\n",
    "    test_scores_std = np.std(dict_expe[\"test_scores\"], axis=1)\n",
    "    train_sizes = dict_expe[\"train_sizes\"]\n",
    "    ax[index].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                    label=\"Training score\")\n",
    "    ax[index].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                    label=\"Cross-validation score\")\n",
    "    ax[index].fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                            train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                            color=\"r\")\n",
    "    ax[index].fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                            test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                            color=\"g\")\n",
    "    ax[index].set_ylim(0.4,1.05)\n",
    "    ax[index].set_title(\"Learning Curve Exstracs (\"+dict_expe[\"name\"]+\"). Mean Acc +- 1 std\")\n",
    "    ax[index].set_xlabel(\"Training Examples\")\n",
    "    ax[index].set_ylabel(\"Accuracy Score\")\n",
    "    ax[index].legend(loc=\"lower right\")\n",
    "    ax[index].grid()\n",
    "    #plt.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def movingAvg(a,threshold=300):\n",
    "    weights = np.repeat(1.0,threshold)/threshold\n",
    "    conv = np.convolve(a,weights,'valid')\n",
    "    return np.append(conv,np.full(threshold-1,conv[conv.size-1]),)\n",
    "\n",
    "def plot_metrics_exstracs(dataTracking, title):\n",
    "    iterations = dataTracking[\"Iteration\"].values\n",
    "    accuracy = dataTracking['Accuracy (approx)'].values\n",
    "    generality = dataTracking['Average Population Generality'].values\n",
    "    macroPop = dataTracking[\"Macropopulation Size\"].values\n",
    "    microPop = dataTracking[\"Micropopulation Size\"].values\n",
    "    mSize = dataTracking[\"Match Set Size\"].values\n",
    "    cSize = dataTracking[\"Correct Set Size\"].values\n",
    "    experience = dataTracking[\"Average Iteration Age of Correct Set Classifiers\"].values\n",
    "    subsumption = dataTracking[\"# Classifiers Subsumed in Iteration\"].values\n",
    "    crossover = dataTracking[\"# Crossover Operations Performed in Iteration\"].values\n",
    "    mutation = dataTracking[\"# Mutation Operations Performed in Iteration\"].values\n",
    "    covering = dataTracking[\"# Covering Operations Performed in Iteration\"].values\n",
    "    deletion = dataTracking[\"# Deletion Operations Performed in Iteration\"].values\n",
    "    rc = dataTracking[\"# Rules Removed via Rule Compaction\"].values\n",
    "\n",
    "    gTime = dataTracking[\"Total Global Time\"].values\n",
    "    mTime = dataTracking[\"Total Matching Time\"].values\n",
    "    covTime = dataTracking[\"Total Covering Time\"].values\n",
    "    crossTime = dataTracking[\"Total Crossover Time\"].values\n",
    "    covTime = dataTracking[\"Total Covering Time\"].values\n",
    "    mutTime = dataTracking[\"Total Mutation Time\"].values\n",
    "    atTime = dataTracking[\"Total Attribute Tracking Time\"].values\n",
    "    initTime = dataTracking[\"Total Model Initialization Time\"].values\n",
    "    rcTime = dataTracking[\"Total Rule Compaction Time\"].values\n",
    "    delTime = dataTracking[\"Total Deletion Time\"].values\n",
    "    subTime = dataTracking[\"Total Subsumption Time\"].values\n",
    "    selTime = dataTracking[\"Total Selection Time\"].values\n",
    "    evalTime = dataTracking[\"Total Evaluation Time\"].values\n",
    "\n",
    "    fig, ax = plt.subplots(2, 3, figsize=(20,10))\n",
    "    ax[0,0].plot(iterations,accuracy,label=\"approx accuracy\")\n",
    "    ax[0,0].plot(iterations,generality,label=\"avg generality\")\n",
    "    ax[0,0].set_xlabel('Iteration')\n",
    "    ax[0,0].set_ylabel('accuracy/generality')\n",
    "    ax[0,0].legend(loc=\"best\")\n",
    "\n",
    "    ax[0,1].plot(iterations,macroPop,label=\"macroPop Size\")\n",
    "    ax[0,1].plot(iterations,microPop,label=\"microPop Size\")\n",
    "    ax[0,1].set_xlabel('Iteration')\n",
    "    ax[0,1].set_ylabel('Macro/MicroPop Size')\n",
    "    ax[0,1].legend(loc=\"best\")\n",
    "\n",
    "    ax[0,2].plot(iterations,mSize,label=\"[M] size\")\n",
    "    ax[0,2].plot(iterations,cSize,label=\"[C] size\")\n",
    "    ax[0,2].plot(iterations,movingAvg(mSize),label=\"[M] size movingAvg\")\n",
    "    ax[0,2].plot(iterations,movingAvg(cSize),label=\"[C] size movingAvg\")\n",
    "    ax[0,2].set_xlabel('Iteration')\n",
    "    ax[0,2].set_ylabel('[M]/[C] size per iteration')\n",
    "    ax[0,2].legend(loc=\"best\")\n",
    "\n",
    "    ax[1,0].scatter(iterations,experience, s=1, linewidths=0, marker=\",\")\n",
    "    ax[1,0].set_xlabel('Iteration')\n",
    "    ax[1,0].set_ylabel('Average [C] Classifier Age')\n",
    "    ax[1,0].legend(loc=\"best\")\n",
    "\n",
    "    ax[1,1].plot(iterations,np.cumsum(subsumption),label=\"Subsumption Count\")\n",
    "    ax[1,1].plot(iterations,np.cumsum(crossover),label=\"Crossover Count\")\n",
    "    ax[1,1].plot(iterations,np.cumsum(mutation),label=\"Mutation Count\")\n",
    "    ax[1,1].plot(iterations,np.cumsum(deletion),label=\"Deletion Count\")\n",
    "    ax[1,1].plot(iterations,np.cumsum(covering),label=\"Covering Count\")\n",
    "    ax[1,1].plot(iterations,np.cumsum(rc),label=\"RC Count\")\n",
    "    ax[1,1].set_xlabel('Iteration')\n",
    "    ax[1,1].set_ylabel('Cumulative Operations Count Over Iterations')\n",
    "    ax[1,1].legend(loc=\"best\")\n",
    "\n",
    "\n",
    "    ax[1,2].plot(iterations,initTime,label=\"Init Time\")\n",
    "    ax[1,2].plot(iterations,mTime+initTime,label=\"Matching Time\")\n",
    "    ax[1,2].plot(iterations,covTime+mTime+initTime,label=\"Covering Time\")\n",
    "    ax[1,2].plot(iterations,selTime+covTime+mTime+initTime,label=\"Selection Time\")\n",
    "    ax[1,2].plot(iterations,crossTime+selTime+covTime+mTime+initTime,label=\"Crossover Time\")\n",
    "    ax[1,2].plot(iterations,mutTime+crossTime+selTime+covTime+mTime+initTime,label=\"Mutation Time\")\n",
    "    ax[1,2].plot(iterations,subTime+mutTime+crossTime+selTime+covTime+mTime+initTime,label=\"Subsumption Time\")\n",
    "    ax[1,2].plot(iterations,atTime+subTime+mutTime+crossTime+selTime+covTime+mTime+initTime,label=\"AT Time\")\n",
    "    ax[1,2].plot(iterations,delTime+atTime+subTime+mutTime+crossTime+selTime+covTime+mTime+initTime,label=\"Deletion Time\")\n",
    "    ax[1,2].plot(iterations,rcTime+delTime+atTime+subTime+mutTime+crossTime+selTime+covTime+mTime+initTime,label=\"RC Time\")\n",
    "    ax[1,2].plot(iterations,evalTime+rcTime+delTime+atTime+subTime+mutTime+crossTime+selTime+covTime+mTime+initTime,label=\"Evaluation Time\")\n",
    "    ax[1,2].plot(iterations,gTime,label=\"Total Time\")\n",
    "    ax[1,2].set_xlabel('Iteration')\n",
    "    ax[1,2].set_ylabel('Cumulative Time (Stacked)')\n",
    "    ax[1,2].legend(loc=\"best\")\n",
    "    fig.suptitle(title, verticalalignment=\"center\", fontsize=\"x-large\", fontweight=\"bold\")\n",
    "    return fig, ax"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_metrics_exstracs(dataTracking[3], title=\"Learning Plots for Exstracs with N=1000\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(len(rules[3]))\n",
    "rules[3].sort_values(\"Numerosity\", ascending=False).head(20)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a8deeaac9d110d020cf02cb90130615d601eccb7528fd115dac771989d3df95a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}