{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#df = pd.read_csv(\"data/compacted_rules.csv\")\n",
    "df = pd.read_csv(\"PredEx/exstracs_train_full/compacted_rules.csv\")\n",
    "df_report = pd.read_csv(\"EHRoes/text_reports.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report = df_report.replace({0.25:1, 0.5:1, 0.75:1})\n",
    "df_report = df_report.replace({\"COM_CCD\":\"COM\", \"COM_MMM\":\"COM\", \"NM_CAP\":\"NM\", \"CFTD\":\"OTHER\", \"NON_CM\":\"OTHER\",\"CM\":\"UNCLEAR\"})\n",
    "count_report_dict_attrb = df_report.count().to_dict()\n",
    "count_report_dict_concl = df_report[\"conclusion\"].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition des paramètres du réseau d'attributs\n",
    "* Noeuds: Attributs ; couleur par sommes de ses numerosité * accuracy\n",
    "* Tailles des Noeuds: Nb de fois qu'on le retrouve\n",
    "* Lien: Si dans la même règle + thickness par occurence, couleur par numérosité * accuracy\n",
    "\n",
    "### Definition des paramètres du réseau attributs - conclusion\n",
    "* Noeuds: Attributs + 1 par conclusions, couleur noeud: par coloration\n",
    "* Tailles des Noeuds: Nb de fois qu'on le retrouve (cb de règles)\n",
    "* Lien: Lien conclusions - attributs avec thickness par occurence, couleur par numérosité * accuracy\n",
    "\n",
    "### Algo:\n",
    "Liste d'attributs unique, créer les noeuds\n",
    "Puis créer les liens en ittérant par ligne du tableau de règles\n",
    "Si le lien existe déjà: modifier la taille du noeuds ?\n",
    "\n",
    "Tableau: id, valeur, titre, label, couleur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "onto = json.load(open(\"EHRoes/ontology.json\", \"r\"))\n",
    "def id_to_name(onto, ids_list, mode=\"full\"):\n",
    "    \"\"\"Map a list of ID of ontology term to their names\n",
    "    Args:\n",
    "        onto (list): ontology json as list\n",
    "        ids_list (_type_): list of ID from ontology to map\n",
    "        mode (str, optional): Mapping mode (id+name or only name) Defaults to \"full\".\n",
    "    Returns:\n",
    "        name_list list : list of nodes names\n",
    "    \"\"\"\n",
    "    json_index = {}\n",
    "    name_list = []\n",
    "    for i in onto:\n",
    "        json_index[i[\"id\"]] = i\n",
    "    if mode == \"full\":\n",
    "        if isinstance(ids_list, list):\n",
    "            for id in ids_list:\n",
    "                try:\n",
    "                    name_list.append(id + \" \" + json_index[id][\"text\"])\n",
    "                except:\n",
    "                    name_list.append(id)\n",
    "        elif isinstance(ids_list, str):\n",
    "            try:\n",
    "                name_list = ids_list + \" \" + json_index[ids_list][\"text\"]\n",
    "            except:\n",
    "                name_list = ids_list\n",
    "    if mode == \"short\":\n",
    "        if isinstance(ids_list, list):\n",
    "            for id in ids_list:\n",
    "                try:\n",
    "                    name_list.append(json_index[id][\"text\"])\n",
    "                except:\n",
    "                    name_list.append(id)\n",
    "        elif isinstance(ids_list, str):\n",
    "            try:\n",
    "                name_list = json_index[ids_list][\"text\"]\n",
    "            except:\n",
    "                name_list = ids_list\n",
    "    return name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Taille des noeuds et des maladies par la quantité dans notre jeu de données de base\n",
    "\n",
    "# All Attrib Nodes\n",
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "full_rules_attrb_split = [] \n",
    "for i in df[\"Specified Attribute Names\"].to_list():\n",
    "    for j in i.split(\", \"):\n",
    "        full_rules_attrb_split.append(j)\n",
    "unique_attrb_count = Counter(full_rules_attrb_split)\n",
    "\n",
    "# All Attrib Edges\n",
    "all_edges = []\n",
    "for i in df[\"Specified Attribute Names\"].to_list():\n",
    "    rule_attrib_list = i.split(\", \")\n",
    "    if len(rule_attrib_list) > 1:\n",
    "        sorted_attrib = sorted(rule_attrib_list)\n",
    "        edges = list(itertools.combinations(rule_attrib_list, 2))\n",
    "        for edge in edges:\n",
    "            all_edges.append(edge)\n",
    "all_edges_count = Counter(all_edges)\n",
    "\n",
    "# All Conclusions Nodes\n",
    "full_rules_concl_split = [] \n",
    "name_dict = {0: \"Centronuclear Myopathy\", 1: \"Core Myopathy\", 2: \"Nemaline Myopathy\"}\n",
    "for i in df[\"conclusion\"].to_list():\n",
    "    full_rules_concl_split.append(name_dict[i])\n",
    "unique_concl_count = Counter(full_rules_concl_split)\n",
    "\n",
    "# All Conclusions Edges IF value is different from 0.\n",
    "all_edges_concl = []\n",
    "all_edges_color = {}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    rule_attrib_list = row[1].split(\", \")\n",
    "    rule_attrib_value = row[0].split(\", \")\n",
    "    sorted_attrib = sorted(rule_attrib_list)\n",
    "    for index, value in enumerate(sorted_attrib):\n",
    "        all_edges_concl.append((name_dict[row[2]], value))\n",
    "        # Set list of edge color depending of attrib status\n",
    "        previous_color = all_edges_color.get((name_dict[row[2]], value), None)\n",
    "        # Probably a dumb way of doing it... yet.\n",
    "        try:\n",
    "            current_value = int(float(rule_attrib_value[index]))\n",
    "        except:\n",
    "            current_value = None\n",
    "        if current_value == None:\n",
    "            all_edges_color[(name_dict[row[2]], value)] = \"#f4b400\"\n",
    "        elif previous_color is None:\n",
    "            if current_value <= 0:\n",
    "                all_edges_color[(name_dict[row[2]], value)] = \"#db4437\"\n",
    "            elif current_value > 0:\n",
    "                all_edges_color[(name_dict[row[2]], value)] = \"#0f9d58\"\n",
    "        else:\n",
    "            if current_value <= 0 and previous_color != \"#db4437\":\n",
    "                all_edges_color[(name_dict[row[2]], value)] = \"#f4b400\"\n",
    "            elif current_value > 0 and previous_color != \"#0f9d58\":\n",
    "                all_edges_color[(name_dict[row[2]], value)] = \"#f4b400\"\n",
    "\n",
    "all_edges_conl_count = Counter(all_edges_concl)\n",
    "\n",
    "# All Conclusions Edges IF value is different from 0.\n",
    "all_edges_concl_nnull = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    rule_attrib_list = row[1].split(\", \")\n",
    "    rule_attrib_value = row[0].split(\", \")\n",
    "    sorted_attrib = sorted(rule_attrib_list)\n",
    "    try:\n",
    "        current_value = int(float(rule_attrib_value[index]))\n",
    "    except:\n",
    "        current_value = None\n",
    "    for index, value in enumerate(sorted_attrib):\n",
    "        if current_value != 0:\n",
    "            all_edges_concl_nnull.append((name_dict[row[2]], value))\n",
    "all_edges_conl_count_nnull = Counter(all_edges_concl_nnull)\n",
    "\n",
    "# All Attrib NodesIF value is different from 0.\n",
    "full_rules_attrb_nnull_split = [] \n",
    "for index, row in df.iterrows():\n",
    "    rule_attrib_list = row[1].split(\", \")\n",
    "    rule_attrib_value = row[0].split(\", \")\n",
    "    sorted_attrib = sorted(rule_attrib_list)\n",
    "    try:\n",
    "        current_value = int(float(rule_attrib_value[index]))\n",
    "    except:\n",
    "        current_value = None\n",
    "    for index, value in enumerate(sorted_attrib):\n",
    "        if current_value != 0:\n",
    "            full_rules_attrb_nnull_split.append(value)\n",
    "    unique_attrb_count_nnull = Counter(full_rules_attrb_nnull_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis import network as net\n",
    "import networkx as nx\n",
    "\n",
    "#net = Network(height='100%', width='100%', bgcolor='#222222', font_color='white', notebook=True)\n",
    "net_1 = net.Network(height='95%', width='70%', notebook=True)\n",
    "for key, value in unique_attrb_count.items():\n",
    "    net_1.add_node(key, label=id_to_name(onto, key, \"short\"), value=value)  \n",
    "for key, value in all_edges_count.items():\n",
    "    net_1.add_edge(key[0], key[1], width=value*3, length=300)\n",
    "#net.show_buttons(filter_=[\"physics\"])\n",
    "net_1.set_options(\"\"\"\n",
    "var options = {\n",
    "  \"layout\": {\n",
    "    \"randomSeed\": 777777\n",
    "    },\n",
    "  \"edges\": {\n",
    "      \"smooth\": true\n",
    "    }\n",
    "}\n",
    "\"\"\")\n",
    "net_1.show(\"PredEx/graph/graph_interaction.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis import network as net\n",
    "\n",
    "#net = Network(height='100%', width='100%', bgcolor='#222222', font_color='white', notebook=True)\n",
    "net_2 = net.Network(height='95%', width='70%', notebook=True)\n",
    "for key, value in unique_attrb_count_nnull.items():\n",
    "    net_2.add_node(key, label=id_to_name(onto, key, \"short\"), value=value, color=\"#4885ed\")\n",
    "for key, value in unique_concl_count.items():\n",
    "    net_2.add_node(key, label=id_to_name(onto, key, \"short\"), value=value, color=\"#db3236\", shape=\"triangle\")  \n",
    "for key, value in all_edges_conl_count_nnull.items():\n",
    "    net_2.add_edge(key[0], key[1], width=value, length=200, color=\"#f4c20d\")\n",
    "#net_2.show_buttons(filter_=[\"physics\"])\n",
    "net_2.set_options(\"\"\"\n",
    "var options = {\n",
    "  \"layout\": {\n",
    "    \"randomSeed\": 777777\n",
    "    },\n",
    "  \"edges\": {\n",
    "      \"smooth\": true\n",
    "    }\n",
    "}\n",
    "\"\"\")\n",
    "net_2.show(\"PredEx/graph/myomap2_these.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis import network as net\n",
    "import networkx as nx\n",
    "\n",
    "#net = Network(height='100%', width='100%', bgcolor='#222222', font_color='white', notebook=True)\n",
    "net_3 = net.Network(height='95%', width='70%', notebook=True)\n",
    "for key, value in unique_attrb_count.items():\n",
    "    #net_3.add_node(key, value=value, color=\"#4885ed\", size=count_report_dict_attrb[key])\n",
    "    net_3.add_node(key, label=id_to_name(onto, key, \"short\"), value=value, color=\"#4885ed\")\n",
    "for key, value in unique_concl_count.items():\n",
    "    net_3.add_node(key, label=id_to_name(onto, key, \"short\"), value=value, color=\"#BA55D3\", shape=\"triangle\")  \n",
    "for key, value in all_edges_conl_count.items():\n",
    "    net_3.add_edge(key[0], key[1], width=value/2, length=250, color=all_edges_color[(key[0],key[1])])\n",
    "#net_3.show_buttons(filter_=[\"physics\"])\n",
    "net_3.set_options(\"\"\"\n",
    "var options = {\n",
    "  \"layout\": {\n",
    "    \"randomSeed\": 777777\n",
    "    },\n",
    "  \"edges\": {\n",
    "      \"smooth\": true\n",
    "    }\n",
    "}\n",
    "\"\"\")\n",
    "net_3.show(\"PredEx/graph/myomap_these.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_attributs_names = set()\n",
    "for i in all_edges_count.keys():\n",
    "    for attributes in i:\n",
    "        all_attributs_names.add(attributes)\n",
    "all_attributs_names = list(all_attributs_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "matrix = np.zeros(shape=(len(all_attributs_names), len(all_attributs_names)))\n",
    "\n",
    "for key, value in all_edges_count.items():\n",
    "    key1 = all_attributs_names.index(key[0])\n",
    "    key2 = all_attributs_names.index(key[1])\n",
    "    matrix[key1, key2] = value\n",
    "    matrix[key2, key1] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import ImageColor\n",
    "import random\n",
    "\n",
    "def load_onto():\n",
    "    with open(os.path.join(\"EHRoes/\", \"ontology.json\"), \"r\") as fp:\n",
    "        onto_tree = json.load(fp)\n",
    "    onto_indexed = dict()\n",
    "    for i in onto_tree:\n",
    "        onto_indexed[i['id']] = i\n",
    "    return onto_indexed\n",
    "\n",
    "def load_color_hex(onto, all_attributs_names):\n",
    "    all_colors = {}\n",
    "    for i in all_attributs_names:\n",
    "        if i in onto.keys():\n",
    "            # color = ImageColor.getcolor(onto[i][\"data\"][\"hex_color\"], \"RGB\")\n",
    "            # rgba_stirng = \"rgba(\" + str(color[0]) + \",\" + str(color[1]) + \",\" + str(color[2]) + \", 0.75)\"\n",
    "            all_colors[i] = onto[i][\"data\"][\"hex_color\"]\n",
    "        else:\n",
    "            # color = [random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)]\n",
    "            # rgba_stirng = \"rgba(\" + str(color[0]) + \",\" + str(color[1]) + \",\" + str(color[2]) + \", 0.75)\"\n",
    "            r = lambda: random.randint(0,255)\n",
    "            all_colors[i] = '#%02X%02X%02X' % (r(),r(),r())\n",
    "    return all_colors\n",
    "\n",
    "def id_to_name(onto, ids_list, mode=\"full\"):\n",
    "    \"\"\"Map a list of ID of ontology term to their names\n",
    "    Args:\n",
    "        onto (list): ontology json as list\n",
    "        ids_list (_type_): list of ID from ontology to map\n",
    "        mode (str, optional): Mapping mode (id+name or only name) Defaults to \"full\".\n",
    "    Returns:\n",
    "        name_list list : list of nodes names\n",
    "    \"\"\"\n",
    "    name_list = {}\n",
    "    if mode == \"full\":\n",
    "        for id in ids_list:\n",
    "            try:\n",
    "                name_list[id] = id + \" \" + onto[id][\"text\"]\n",
    "            except:\n",
    "                name_list[id] = id\n",
    "\n",
    "    if mode == \"short\":         \n",
    "        for id in ids_list:\n",
    "            try:\n",
    "                name_list[id] = onto[id][\"text\"]\n",
    "            except:\n",
    "                name_list[id] = id\n",
    "    return name_list\n",
    "\n",
    "ontology = load_onto()\n",
    "all_colors = load_color_hex(ontology, all_attributs_names)\n",
    "full_name_nodes = id_to_name(ontology, all_attributs_names, mode=\"short\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for index, value in all_edges_count.items():\n",
    "    rows.append([index[0], index[1], value, full_name_nodes[index[0]],all_colors[index[0]]])\n",
    "data_chord = pd.DataFrame(rows, columns=[\"source\", \"target\", \"value\", \"name\", \"color\"])\n",
    "\n",
    "source = data_chord[\"source\"].to_list()\n",
    "target = data_chord[\"target\"].to_list()\n",
    "both_src_tgt = source + target\n",
    "both_src_tgt = list(set(both_src_tgt))\n",
    "dict_index = {}\n",
    "for i,v in enumerate(both_src_tgt):\n",
    "    dict_index[v] = i\n",
    "data_chord[\"source\"].replace(dict_index, inplace=True)\n",
    "data_chord[\"target\"].replace(dict_index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "from holoviews import opts, dim\n",
    "\n",
    "#hv.notebook_extension(\"bokeh\")\n",
    "hv.extension('matplotlib')\n",
    "hv.output(size=300)\n",
    "\n",
    "links = data_chord[[\"source\",\"target\",\"value\"]]\n",
    "nodes = pd.DataFrame(data_chord[[\"target\",\"name\", \"color\"]]).drop_duplicates()\n",
    "nodes.rename(columns={\"target\":\"index\"}, inplace=True)\n",
    "nodes.set_index(\"index\", drop=False, inplace=True)\n",
    "nodes = nodes.sort_index().reset_index(drop=True)\n",
    "nodes['index'] = nodes.index\n",
    "nodes = hv.Dataset(nodes, 'index')\n",
    "chord = hv.Chord((links, nodes)).select(value=(10, None))\n",
    "chord.opts(\n",
    "     hv.opts.Chord(cmap='Category20', edge_cmap='Category20', edge_color=dim('source').str(), \n",
    "                labels='name', node_color=dim('index').str()))\n",
    "chord.opts(frame_width=800, frame_height=800)\n",
    "#hv.save(chord, 'interaction.png', fmt='png')\n",
    "hv.save(chord, 'PredEx/graph/chord_these.html', backend='bokeh')\n",
    "hv.save(chord, 'PredEx/graph/chord_plot.png', fmt='png')\n",
    "chord"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9dd19723d1839bcc84cb9daad10928a0e1f578211ad347c6661afee120e3f511"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('predex-h8c-vB0n-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
